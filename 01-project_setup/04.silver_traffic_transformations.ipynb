{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ce53e5f2-7a43-43da-819c-ab39baaec66c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.widgets.text(name=\"env\",defaultValue='',label='Enter the environment in lower case')\n",
    "env = dbutils.widgets.get(\"env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "7a2ce673-b821-4f9a-8e27-79f5c63d8147",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run \"./commons\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "19de88b9-bfc8-47fd-acd4-de4390cfb58f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "### Reading from bronze table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dab2fcb3-09a1-4cb2-ad05-f3ed176498f3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def read_BronzeTrafficTable(environment):\n",
    "    print('Reading the Bronze Table Data : ',end='')\n",
    "    df_bronzeTraffic = (spark.readStream.table(f\"`{environment}_catalog`.`bronze`.raw_traffic\"))\n",
    "    print(f'Reading {environment}_catalog.bronze.raw_traffic Success!')\n",
    "    return df_bronzeTraffic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3b3c0971-cfbf-44ba-a6eb-52c192145a59",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## quality check 1: Handing duplicate rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2030eac0-90a7-46b7-a3da-9a89e7ed4c73",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## quality check 2: Handling NULL values by replacing them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8e15db1d-34ed-4a5a-a1e4-4838cf3575bb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Getting count of Electric vehicles by creating new column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "64bcbdc9-a60a-4620-86a5-8db07c42aa7f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def ev_Count(df):\n",
    "    print('Creating Electric Vehicles Count Column : ', end='')\n",
    "    from pyspark.sql.functions import col\n",
    "    df_ev = df.withColumn('Electric_Vehicles_Count', col('EV_Car') + col('EV_Bike'))\n",
    "    \n",
    "    print('Success!! ')\n",
    "    return df_ev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "28dc7132-9867-463a-abec-a079d4e45039",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Creating columns to get Count of all motor vehicles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "02661a7f-337f-4272-aad2-88a25ae7a812",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def Motor_Count(df):\n",
    "    print('Creating All Motor Vehicles Count Column : ', end='')\n",
    "    from pyspark.sql.functions import col\n",
    "    df_motor = df.withColumn('Motor_Vehicles_Count',\n",
    "                            col('Electric_Vehicles_Count') + col('Two_wheeled_motor_vehicles') + col('Cars_and_taxis') + col('Buses_and_coaches') + col('LGV_Type') + col('HGV_Type')\n",
    "                            )\n",
    "    \n",
    "    print('Success!! ')\n",
    "    return df_motor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e24378eb-c813-4556-bfdd-080ede7e844c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Creating Transformed Time column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f0dffb21-6ed8-4377-9dfd-bdd4e6e4da44",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def create_TransformedTime(df):\n",
    "    from pyspark.sql.functions import current_timestamp\n",
    "    print('Creating Transformed Time column : ',end='')\n",
    "    df_timestamp = df.withColumn('Transformed_Time', current_timestamp())\n",
    "    print('Success!!')\n",
    "    return df_timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ed0ccb3f-5f41-4122-a474-a73f558fd993",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Writing the Transformed data to Silver_Traffic Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b742bde-034e-412c-b8a0-848f8abecbd4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def write_Traffic_SilverTable(StreamingDF,environment):\n",
    "    print('Writing the silver_traffic Data : ',end='') \n",
    "\n",
    "    write_StreamSilver = (StreamingDF.writeStream\n",
    "                .format('delta')\n",
    "                .option('checkpointLocation',checkpoint+ \"/SilverTrafficLoad/Checkpt/\")\n",
    "                .outputMode('append')\n",
    "                .queryName(\"SilverTrafficWriteStream\")\n",
    "                .trigger(availableNow=True)\n",
    "                .toTable(f\"`{environment}_catalog`.`silver`.`silver_traffic`\"))\n",
    "    \n",
    "    write_StreamSilver.awaitTermination()\n",
    "    print(f'Writing `{environment}_catalog`.`silver`.`silver_traffic` Success!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "beb34603-7450-4983-9a40-5beea2c95489",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "### Calling functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d44a5e4b-dbac-4f33-bb3b-37cdd8acd95a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## Reading the bronze traffic data\n",
    "df_trafficdata = read_BronzeTrafficTable(env)\n",
    "\n",
    "# To remove duplicate rows\n",
    "df_dups = remove_Dups(df_trafficdata)\n",
    "\n",
    "# To raplce any NULL values\n",
    "Allcolumns =df_dups.schema.names\n",
    "df_nulls = handle_NULLs(df_dups,Allcolumns)\n",
    "\n",
    "## To get the total EV_Count\n",
    "df_ev = ev_Count(df_nulls)\n",
    "\n",
    "## To get the Total Motor vehicle count\n",
    "df_motor = Motor_Count(df_ev)\n",
    "\n",
    "## Calling Transformed time function\n",
    "df_final = create_TransformedTime(df_motor)\n",
    "\n",
    "## Writing to silver_traffic\n",
    "write_Traffic_SilverTable(df_final, env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "286060f1-a5df-4cfd-a437-2d1e6cbf3f7d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(spark.sql(f\"SELECT Count(*) FROM `{env}_catalog`.`silver`.`silver_traffic` LIMIT 10\"))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "04.silver_traffic_transformations",
   "widgets": {
    "env": {
     "currentValue": "dev",
     "nuid": "ece46db5-e37f-467f-9f06-1ef4bbf169de",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": "Enter the environment in lower case",
      "name": "env",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": "Enter the environment in lower case",
      "name": "env",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
